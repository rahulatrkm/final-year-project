{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GazeCapture.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulatrkm/final-year-project/blob/master/GazeCapture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u28VYTc30G27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math, shutil, os, time, argparse, json, re, sys\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6LGqBVWkKJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Prepares the GazeCapture dataset for use with the pytorch code. Crops images, compiles JSONs into metadata.mat\n",
        "Author: Petr Kellnhofer ( pkel_lnho (at) gmai_l.com // remove underscores and spaces), 2018. \n",
        "Website: http://gazecapture.csail.mit.edu/\n",
        "Cite:\n",
        "Eye Tracking for Everyone\n",
        "K.Krafka*, A. Khosla*, P. Kellnhofer, H. Kannan, S. Bhandarkar, W. Matusik and A. Torralba\n",
        "IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016\n",
        "@inproceedings{cvpr2016_gazecapture,\n",
        "Author = {Kyle Krafka and Aditya Khosla and Petr Kellnhofer and Harini Kannan and Suchendra Bhandarkar and Wojciech Matusik and Antonio Torralba},\n",
        "Title = {Eye Tracking for Everyone},\n",
        "Year = {2016},\n",
        "Booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}\n",
        "}\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd2MSeffoMTL",
        "colab_type": "code",
        "outputId": "e024a666-2cc1-4c49-d60a-6bb95c41ff82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "\n",
        "parser = argparse.ArgumentParser(description='iTracker-pytorch-PrepareDataset.')\n",
        "parser.add_argument('--dataset_path', help=\"Path to extracted files. It should have folders called '%%05d' in it.\")\n",
        "parser.add_argument('--output_path', default=None, help=\"Where to write the output. Can be the same as dataset_path if you wish (=default).\")\n",
        "args = parser.parse_args()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--dataset_path DATASET_PATH]\n",
            "                             [--output_path OUTPUT_PATH]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-79c4c044-e284-45fe-ac9f-b08fc94ee253.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LezRJADph9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    if args.output_path is None:\n",
        "        args.output_path = args.dataset_path\n",
        "    \n",
        "    if args.dataset_path is None or not os.path.isdir(args.dataset_path):\n",
        "        raise RuntimeError('No such dataset folder %s!' % args.dataset_path)\n",
        "\n",
        "    preparePath(args.output_path)\n",
        "\n",
        "    # list recordings\n",
        "    recordings = os.listdir(args.dataset_path)\n",
        "    recordings = np.array(recordings, np.object)\n",
        "    recordings = recordings[[os.path.isdir(os.path.join(args.dataset_path, r)) for r in recordings]]\n",
        "    recordings.sort()\n",
        "\n",
        "    # Output structure\n",
        "    meta = {\n",
        "        'labelRecNum': [],\n",
        "        'frameIndex': [],\n",
        "        'labelDotXCam': [],\n",
        "        'labelDotYCam': [],\n",
        "        'labelFaceGrid': [],\n",
        "    }\n",
        "\n",
        "    for i,recording in enumerate(recordings):\n",
        "        print('[%d/%d] Processing recording %s (%.2f%%)' % (i, len(recordings), recording, i / len(recordings) * 100))\n",
        "        recDir = os.path.join(args.dataset_path, recording)\n",
        "        recDirOut = os.path.join(args.output_path, recording)\n",
        "\n",
        "        # Read JSONs\n",
        "        appleFace = readJson(os.path.join(recDir, 'appleFace.json'))\n",
        "        if appleFace is None:\n",
        "            continue\n",
        "        appleLeftEye = readJson(os.path.join(recDir, 'appleLeftEye.json'))\n",
        "        if appleLeftEye is None:\n",
        "            continue\n",
        "        appleRightEye = readJson(os.path.join(recDir, 'appleRightEye.json'))\n",
        "        if appleRightEye is None:\n",
        "            continue\n",
        "        dotInfo = readJson(os.path.join(recDir, 'dotInfo.json'))\n",
        "        if dotInfo is None:\n",
        "            continue\n",
        "        faceGrid = readJson(os.path.join(recDir, 'faceGrid.json'))\n",
        "        if faceGrid is None:\n",
        "            continue\n",
        "        frames = readJson(os.path.join(recDir, 'frames.json'))\n",
        "        if frames is None:\n",
        "            continue\n",
        "        # info = readJson(os.path.join(recDir, 'info.json'))\n",
        "        # if info is None:\n",
        "        #     continue\n",
        "        # screen = readJson(os.path.join(recDir, 'screen.json'))\n",
        "        # if screen is None:\n",
        "        #     continue\n",
        "\n",
        "        facePath = preparePath(os.path.join(recDirOut, 'appleFace'))\n",
        "        leftEyePath = preparePath(os.path.join(recDirOut, 'appleLeftEye'))\n",
        "        rightEyePath = preparePath(os.path.join(recDirOut, 'appleRightEye'))\n",
        "\n",
        "        # Preprocess\n",
        "        allValid = np.logical_and(np.logical_and(appleFace['IsValid'], appleLeftEye['IsValid']), np.logical_and(appleRightEye['IsValid'], faceGrid['IsValid']))\n",
        "        if not np.any(allValid):\n",
        "            continue\n",
        "\n",
        "        frames = np.array([int(re.match('(\\d{5})\\.jpg$', x).group(1)) for x in frames])\n",
        "\n",
        "        bboxFromJson = lambda data: np.stack((data['X'], data['Y'], data['W'],data['H']), axis=1).astype(int)\n",
        "        faceBbox = bboxFromJson(appleFace) + [-1,-1,1,1] # for compatibility with matlab code\n",
        "        leftEyeBbox = bboxFromJson(appleLeftEye) + [0,-1,0,0]\n",
        "        rightEyeBbox = bboxFromJson(appleRightEye) + [0,-1,0,0]\n",
        "        leftEyeBbox[:,:2] += faceBbox[:,:2] # relative to face\n",
        "        rightEyeBbox[:,:2] += faceBbox[:,:2]\n",
        "        faceGridBbox = bboxFromJson(faceGrid)\n",
        "\n",
        "\n",
        "        for j,frame in enumerate(frames):\n",
        "            # Can we use it?\n",
        "            if not allValid[j]:\n",
        "                continue\n",
        "\n",
        "            # Load image\n",
        "            imgFile = os.path.join(recDir, 'frames', '%05d.jpg' % frame)\n",
        "            if not os.path.isfile(imgFile):\n",
        "                logError('Warning: Could not read image file %s!' % imgFile)\n",
        "                continue\n",
        "            img = Image.open(imgFile)        \n",
        "            if img is None:\n",
        "                logError('Warning: Could not read image file %s!' % imgFile)\n",
        "                continue\n",
        "            img = np.array(img.convert('RGB'))\n",
        "\n",
        "            # Crop images\n",
        "            imFace = cropImage(img, faceBbox[j,:])\n",
        "            imEyeL = cropImage(img, leftEyeBbox[j,:])\n",
        "            imEyeR = cropImage(img, rightEyeBbox[j,:])\n",
        "\n",
        "            # Save images\n",
        "            Image.fromarray(imFace).save(os.path.join(facePath, '%05d.jpg' % frame), quality=95)\n",
        "            Image.fromarray(imEyeL).save(os.path.join(leftEyePath, '%05d.jpg' % frame), quality=95)\n",
        "            Image.fromarray(imEyeR).save(os.path.join(rightEyePath, '%05d.jpg' % frame), quality=95)\n",
        "\n",
        "            # Collect metadata\n",
        "            meta['labelRecNum'] += [int(recording)]\n",
        "            meta['frameIndex'] += [frame]\n",
        "            meta['labelDotXCam'] += [dotInfo['XCam'][j]]\n",
        "            meta['labelDotYCam'] += [dotInfo['YCam'][j]]\n",
        "            meta['labelFaceGrid'] += [faceGridBbox[j,:]]\n",
        "\n",
        "    \n",
        "    # Integrate\n",
        "    meta['labelRecNum'] = np.stack(meta['labelRecNum'], axis = 0).astype(np.int16)\n",
        "    meta['frameIndex'] = np.stack(meta['frameIndex'], axis = 0).astype(np.int32)\n",
        "    meta['labelDotXCam'] = np.stack(meta['labelDotXCam'], axis = 0)\n",
        "    meta['labelDotYCam'] = np.stack(meta['labelDotYCam'], axis = 0)\n",
        "    meta['labelFaceGrid'] = np.stack(meta['labelFaceGrid'], axis = 0).astype(np.uint8)\n",
        "\n",
        "    # Load reference metadata\n",
        "    print('Will compare to the reference GitHub dataset metadata.mat...')\n",
        "    reference = sio.loadmat('./reference_metadata.mat', struct_as_record=False) \n",
        "    reference['labelRecNum'] = reference['labelRecNum'].flatten()\n",
        "    reference['frameIndex'] = reference['frameIndex'].flatten()\n",
        "    reference['labelDotXCam'] = reference['labelDotXCam'].flatten()\n",
        "    reference['labelDotYCam'] = reference['labelDotYCam'].flatten()\n",
        "    reference['labelTrain'] = reference['labelTrain'].flatten()\n",
        "    reference['labelVal'] = reference['labelVal'].flatten()\n",
        "    reference['labelTest'] = reference['labelTest'].flatten()\n",
        "\n",
        "    # Find mapping\n",
        "    mKey = np.array(['%05d_%05d' % (rec, frame) for rec, frame in zip(meta['labelRecNum'], meta['frameIndex'])], np.object)\n",
        "    rKey = np.array(['%05d_%05d' % (rec, frame) for rec, frame in zip(reference['labelRecNum'], reference['frameIndex'])], np.object)\n",
        "    mIndex = {k: i for i,k in enumerate(mKey)}\n",
        "    rIndex = {k: i for i,k in enumerate(rKey)}\n",
        "    mToR = np.zeros((len(mKey,)),int) - 1\n",
        "    for i,k in enumerate(mKey):\n",
        "        if k in rIndex:\n",
        "            mToR[i] = rIndex[k]\n",
        "        else:\n",
        "            logError('Did not find rec_frame %s from the new dataset in the reference dataset!' % k)\n",
        "    rToM = np.zeros((len(rKey,)),int) - 1\n",
        "    for i,k in enumerate(rKey):\n",
        "        if k in mIndex:\n",
        "            rToM[i] = mIndex[k]\n",
        "        else:\n",
        "            logError('Did not find rec_frame %s from the reference dataset in the new dataset!' % k, critical = False)\n",
        "            #break\n",
        "\n",
        "    # Copy split from reference\n",
        "    meta['labelTrain'] = np.zeros((len(meta['labelRecNum'],)),np.bool)\n",
        "    meta['labelVal'] = np.ones((len(meta['labelRecNum'],)),np.bool) # default choice\n",
        "    meta['labelTest'] = np.zeros((len(meta['labelRecNum'],)),np.bool)\n",
        "\n",
        "    validMappingMask = mToR >= 0\n",
        "    meta['labelTrain'][validMappingMask] = reference['labelTrain'][mToR[validMappingMask]]\n",
        "    meta['labelVal'][validMappingMask] = reference['labelVal'][mToR[validMappingMask]]\n",
        "    meta['labelTest'][validMappingMask] = reference['labelTest'][mToR[validMappingMask]]\n",
        "\n",
        "    # Write out metadata\n",
        "    metaFile = os.path.join(args.output_path, 'metadata.mat')\n",
        "    print('Writing out the metadata.mat to %s...' % metaFile)\n",
        "    sio.savemat(metaFile, meta)\n",
        "    \n",
        "    # Statistics\n",
        "    nMissing = np.sum(rToM < 0)\n",
        "    nExtra = np.sum(mToR < 0)\n",
        "    totalMatch = len(mKey) == len(rKey) and np.all(np.equal(mKey, rKey))\n",
        "    print('======================\\n\\tSummary\\n======================')    \n",
        "    print('Total added %d frames from %d recordings.' % (len(meta['frameIndex']), len(np.unique(meta['labelRecNum']))))\n",
        "    if nMissing > 0:\n",
        "        print('There are %d frames missing in the new dataset. This may affect the results. Check the log to see which files are missing.' % nMissing)\n",
        "    else:\n",
        "        print('There are no missing files.')\n",
        "    if nExtra > 0:\n",
        "        print('There are %d extra frames in the new dataset. This is generally ok as they were marked for validation split only.' % nExtra)\n",
        "    else:\n",
        "        print('There are no extra files that were not in the reference dataset.')\n",
        "    if totalMatch:\n",
        "        print('The new metadata.mat is an exact match to the reference from GitHub (including ordering)')\n",
        "\n",
        "    #import pdb; pdb.set_trace()\n",
        "    input(\"Press Enter to continue...\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def readJson(filename):\n",
        "    if not os.path.isfile(filename):\n",
        "        logError('Warning: No such file %s!' % filename)\n",
        "        return None\n",
        "\n",
        "    with open(filename) as f:\n",
        "        try:\n",
        "            data = json.load(f)\n",
        "        except:\n",
        "            data = None\n",
        "\n",
        "    if data is None:\n",
        "        logError('Warning: Could not read file %s!' % filename)\n",
        "        return None\n",
        "\n",
        "    return data\n",
        "\n",
        "def preparePath(path, clear = False):\n",
        "    if not os.path.isdir(path):\n",
        "        os.makedirs(path, 0o777)\n",
        "    if clear:\n",
        "        files = os.listdir(path)\n",
        "        for f in files:\n",
        "            fPath = os.path.join(path, f)\n",
        "            if os.path.isdir(fPath):\n",
        "                shutil.rmtree(fPath)\n",
        "            else:\n",
        "                os.remove(fPath)\n",
        "\n",
        "    return path\n",
        "\n",
        "def logError(msg, critical = False):\n",
        "    print(msg)\n",
        "    if critical:\n",
        "        sys.exit(1)\n",
        "\n",
        "\n",
        "def cropImage(img, bbox):\n",
        "    bbox = np.array(bbox, int)\n",
        "\n",
        "    aSrc = np.maximum(bbox[:2], 0)\n",
        "    bSrc = np.minimum(bbox[:2] + bbox[2:], (img.shape[1], img.shape[0]))\n",
        "\n",
        "    aDst = aSrc - bbox[:2]\n",
        "    bDst = aDst + (bSrc - aSrc)\n",
        "\n",
        "    res = np.zeros((bbox[3], bbox[2], img.shape[2]), img.dtype)    \n",
        "    res[aDst[1]:bDst[1],aDst[0]:bDst[0],:] = img[aSrc[1]:bSrc[1],aSrc[0]:bSrc[0],:]\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    print('DONE')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LyvO9GO1Xq8",
        "colab_type": "text"
      },
      "source": [
        "## Creating my own model.\n",
        "This part of the code is implemented with a little aspiration from [this project](https://colab.research.google.com/drive/1eU0fWMDtXROxY9KMgp4wLMlzc2ufMuim)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA_DkwX4zi2E",
        "colab_type": "code",
        "outputId": "03e174d7-8bea-49f2-d54d-ec97e10312f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torchvision import transforms, models\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "    \n",
        "# pillow version of 5.3.0 will be needed\n",
        "# Uninstalling the older version first\n",
        "!pip uninstall -y Pillow\n",
        "# installing the new one\n",
        "!pip install Pillow==5.3.0\n",
        "# import the new one\n",
        "import PIL\n",
        "print(PIL.PILLOW_VERSION)\n",
        "#Few more imports to test environments\n",
        "!pip install --no-cache-dir -I pillow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n",
            "Uninstalling Pillow-5.3.0:\n",
            "  Successfully uninstalled Pillow-5.3.0\n",
            "Collecting Pillow==5.3.0\n",
            "  Using cached https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "Successfully installed Pillow-5.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "5.3.0\n",
            "Collecting pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5c/0e94e689de2476c4c5e644a3bd223a1c1b9e2bdb7c510191750be74fa786/Pillow-6.2.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 7.2MB/s \n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "Successfully installed pillow-6.2.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0Gts_7L2s6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports here\n",
        "%matplotlib inline\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, models, transforms\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coEEkABM7Cvf",
        "colab_type": "text"
      },
      "source": [
        "### Upload the dataset for the current runtime.\n",
        "After uploading the dataset unzip using `tar`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJyRyRoegicp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51dff083-99a5-4327-9986-e458f1e80a1f"
      },
      "source": [
        "!mkdir dataset"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘dataset’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl99PYXxgqun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq first\\ three.zip -C dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1buqOQgF7HGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf 00005.tar.gz -C first\\ three"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRvgTveaDYEC",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the data for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDPnl5pcA5Ix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4da1f855-a32e-42da-a966-9b0677f06f0c"
      },
      "source": [
        "import math, shutil, os, time, argparse, json, re, sys\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "'''\n",
        "Prepares the GazeCapture dataset for use with the pytorch code. Crops images, compiles JSONs into metadata.mat\n",
        "\n",
        "Author: Petr Kellnhofer ( pkel_lnho (at) gmai_l.com // remove underscores and spaces), 2018. \n",
        "\n",
        "Website: http://gazecapture.csail.mit.edu/\n",
        "\n",
        "Cite:\n",
        "\n",
        "Eye Tracking for Everyone\n",
        "K.Krafka*, A. Khosla*, P. Kellnhofer, H. Kannan, S. Bhandarkar, W. Matusik and A. Torralba\n",
        "IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016\n",
        "\n",
        "@inproceedings{cvpr2016_gazecapture,\n",
        "Author = {Kyle Krafka and Aditya Khosla and Petr Kellnhofer and Harini Kannan and Suchendra Bhandarkar and Wojciech Matusik and Antonio Torralba},\n",
        "Title = {Eye Tracking for Everyone},\n",
        "Year = {2016},\n",
        "Booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}\n",
        "}\n",
        "\n",
        "'''\n",
        "\n",
        "def main():\n",
        "    # list recordings\n",
        "    recordings = os.listdir(args.dataset_path)\n",
        "    recordings = np.array(recordings, np.object)\n",
        "    recordings = recordings[[os.path.isdir(os.path.join(args.dataset_path, r)) for r in recordings]]\n",
        "    recordings.sort()\n",
        "\n",
        "    # Output structure\n",
        "    meta = {\n",
        "        'labelRecNum': [],\n",
        "        'frameIndex': [],\n",
        "        'labelDotXCam': [],\n",
        "        'labelDotYCam': [],\n",
        "        'labelFaceGrid': [],\n",
        "    }\n",
        "\n",
        "    for i,recording in enumerate(recordings):\n",
        "        print('[%d/%d] Processing recording %s (%.2f%%)' % (i, len(recordings), recording, i / len(recordings) * 100))\n",
        "        recDir = os.path.join(args.dataset_path, recording)\n",
        "        recDirOut = os.path.join(args.output_path, recording)\n",
        "\n",
        "        # Read JSONs\n",
        "        appleFace = readJson(os.path.join(recDir, 'appleFace.json'))\n",
        "        if appleFace is None:\n",
        "            continue\n",
        "        appleLeftEye = readJson(os.path.join(recDir, 'appleLeftEye.json'))\n",
        "        if appleLeftEye is None:\n",
        "            continue\n",
        "        appleRightEye = readJson(os.path.join(recDir, 'appleRightEye.json'))\n",
        "        if appleRightEye is None:\n",
        "            continue\n",
        "        dotInfo = readJson(os.path.join(recDir, 'dotInfo.json'))\n",
        "        if dotInfo is None:\n",
        "            continue\n",
        "        faceGrid = readJson(os.path.join(recDir, 'faceGrid.json'))\n",
        "        if faceGrid is None:\n",
        "            continue\n",
        "        frames = readJson(os.path.join(recDir, 'frames.json'))\n",
        "        if frames is None:\n",
        "            continue\n",
        "        # info = readJson(os.path.join(recDir, 'info.json'))\n",
        "        # if info is None:\n",
        "        #     continue\n",
        "        # screen = readJson(os.path.join(recDir, 'screen.json'))\n",
        "        # if screen is None:\n",
        "        #     continue\n",
        "\n",
        "        facePath = preparePath(os.path.join(recDirOut, 'appleFace'))\n",
        "        leftEyePath = preparePath(os.path.join(recDirOut, 'appleLeftEye'))\n",
        "        rightEyePath = preparePath(os.path.join(recDirOut, 'appleRightEye'))\n",
        "\n",
        "        # Preprocess\n",
        "        allValid = np.logical_and(np.logical_and(appleFace['IsValid'], appleLeftEye['IsValid']), np.logical_and(appleRightEye['IsValid'], faceGrid['IsValid']))\n",
        "        if not np.any(allValid):\n",
        "            continue\n",
        "\n",
        "        frames = np.array([int(re.match('(\\d{5})\\.jpg$', x).group(1)) for x in frames])\n",
        "\n",
        "        bboxFromJson = lambda data: np.stack((data['X'], data['Y'], data['W'],data['H']), axis=1).astype(int)\n",
        "        faceBbox = bboxFromJson(appleFace) + [-1,-1,1,1] # for compatibility with matlab code\n",
        "        leftEyeBbox = bboxFromJson(appleLeftEye) + [0,-1,0,0]\n",
        "        rightEyeBbox = bboxFromJson(appleRightEye) + [0,-1,0,0]\n",
        "        leftEyeBbox[:,:2] += faceBbox[:,:2] # relative to face\n",
        "        rightEyeBbox[:,:2] += faceBbox[:,:2]\n",
        "        faceGridBbox = bboxFromJson(faceGrid)\n",
        "\n",
        "\n",
        "        for j,frame in enumerate(frames):\n",
        "            # Can we use it?\n",
        "            if not allValid[j]:\n",
        "                continue\n",
        "\n",
        "            # Load image\n",
        "            imgFile = os.path.join(recDir, 'frames', '%05d.jpg' % frame)\n",
        "            if not os.path.isfile(imgFile):\n",
        "                logError('Warning: Could not read image file %s!' % imgFile)\n",
        "                continue\n",
        "            img = Image.open(imgFile)        \n",
        "            if img is None:\n",
        "                logError('Warning: Could not read image file %s!' % imgFile)\n",
        "                continue\n",
        "            img = np.array(img.convert('RGB'))\n",
        "\n",
        "            # Crop images\n",
        "            imFace = cropImage(img, faceBbox[j,:])\n",
        "            imEyeL = cropImage(img, leftEyeBbox[j,:])\n",
        "            imEyeR = cropImage(img, rightEyeBbox[j,:])\n",
        "\n",
        "            # Save images\n",
        "            Image.fromarray(imFace).save(os.path.join(facePath, '%05d.jpg' % frame), quality=95)\n",
        "            Image.fromarray(imEyeL).save(os.path.join(leftEyePath, '%05d.jpg' % frame), quality=95)\n",
        "            Image.fromarray(imEyeR).save(os.path.join(rightEyePath, '%05d.jpg' % frame), quality=95)\n",
        "\n",
        "            # Collect metadata\n",
        "            meta['labelRecNum'] += [int(recording)]\n",
        "            meta['frameIndex'] += [frame]\n",
        "            meta['labelDotXCam'] += [dotInfo['XCam'][j]]\n",
        "            meta['labelDotYCam'] += [dotInfo['YCam'][j]]\n",
        "            meta['labelFaceGrid'] += [faceGridBbox[j,:]]\n",
        "\n",
        "    \n",
        "    # Integrate\n",
        "    meta['labelRecNum'] = np.stack(meta['labelRecNum'], axis = 0).astype(np.int16)\n",
        "    meta['frameIndex'] = np.stack(meta['frameIndex'], axis = 0).astype(np.int32)\n",
        "    meta['labelDotXCam'] = np.stack(meta['labelDotXCam'], axis = 0)\n",
        "    meta['labelDotYCam'] = np.stack(meta['labelDotYCam'], axis = 0)\n",
        "    meta['labelFaceGrid'] = np.stack(meta['labelFaceGrid'], axis = 0).astype(np.uint8)\n",
        "\n",
        "    # Load reference metadata\n",
        "    print('Will compare to the reference GitHub dataset metadata.mat...')\n",
        "    reference = sio.loadmat('./reference_metadata.mat', struct_as_record=False) \n",
        "    reference['labelRecNum'] = reference['labelRecNum'].flatten()\n",
        "    reference['frameIndex'] = reference['frameIndex'].flatten()\n",
        "    reference['labelDotXCam'] = reference['labelDotXCam'].flatten()\n",
        "    reference['labelDotYCam'] = reference['labelDotYCam'].flatten()\n",
        "    reference['labelTrain'] = reference['labelTrain'].flatten()\n",
        "    reference['labelVal'] = reference['labelVal'].flatten()\n",
        "    reference['labelTest'] = reference['labelTest'].flatten()\n",
        "\n",
        "    # Find mapping\n",
        "    mKey = np.array(['%05d_%05d' % (rec, frame) for rec, frame in zip(meta['labelRecNum'], meta['frameIndex'])], np.object)\n",
        "    rKey = np.array(['%05d_%05d' % (rec, frame) for rec, frame in zip(reference['labelRecNum'], reference['frameIndex'])], np.object)\n",
        "    mIndex = {k: i for i,k in enumerate(mKey)}\n",
        "    rIndex = {k: i for i,k in enumerate(rKey)}\n",
        "    mToR = np.zeros((len(mKey,)),int) - 1\n",
        "    for i,k in enumerate(mKey):\n",
        "        if k in rIndex:\n",
        "            mToR[i] = rIndex[k]\n",
        "        else:\n",
        "            logError('Did not find rec_frame %s from the new dataset in the reference dataset!' % k)\n",
        "    rToM = np.zeros((len(rKey,)),int) - 1\n",
        "    for i,k in enumerate(rKey):\n",
        "        if k in mIndex:\n",
        "            rToM[i] = mIndex[k]\n",
        "        else:\n",
        "            logError('Did not find rec_frame %s from the reference dataset in the new dataset!' % k, critical = False)\n",
        "            #break\n",
        "\n",
        "    # Copy split from reference\n",
        "    meta['labelTrain'] = np.zeros((len(meta['labelRecNum'],)),np.bool)\n",
        "    meta['labelVal'] = np.ones((len(meta['labelRecNum'],)),np.bool) # default choice\n",
        "    meta['labelTest'] = np.zeros((len(meta['labelRecNum'],)),np.bool)\n",
        "\n",
        "    validMappingMask = mToR >= 0\n",
        "    meta['labelTrain'][validMappingMask] = reference['labelTrain'][mToR[validMappingMask]]\n",
        "    meta['labelVal'][validMappingMask] = reference['labelVal'][mToR[validMappingMask]]\n",
        "    meta['labelTest'][validMappingMask] = reference['labelTest'][mToR[validMappingMask]]\n",
        "\n",
        "    # Write out metadata\n",
        "    metaFile = os.path.join(args.output_path, 'metadata.mat')\n",
        "    print('Writing out the metadata.mat to %s...' % metaFile)\n",
        "    sio.savemat(metaFile, meta)\n",
        "    \n",
        "    # Statistics\n",
        "    nMissing = np.sum(rToM < 0)\n",
        "    nExtra = np.sum(mToR < 0)\n",
        "    totalMatch = len(mKey) == len(rKey) and np.all(np.equal(mKey, rKey))\n",
        "    print('======================\\n\\tSummary\\n======================')    \n",
        "    print('Total added %d frames from %d recordings.' % (len(meta['frameIndex']), len(np.unique(meta['labelRecNum']))))\n",
        "    if nMissing > 0:\n",
        "        print('There are %d frames missing in the new dataset. This may affect the results. Check the log to see which files are missing.' % nMissing)\n",
        "    else:\n",
        "        print('There are no missing files.')\n",
        "    if nExtra > 0:\n",
        "        print('There are %d extra frames in the new dataset. This is generally ok as they were marked for validation split only.' % nExtra)\n",
        "    else:\n",
        "        print('There are no extra files that were not in the reference dataset.')\n",
        "    if totalMatch:\n",
        "        print('The new metadata.mat is an exact match to the reference from GitHub (including ordering)')\n",
        "\n",
        "    #import pdb; pdb.set_trace()\n",
        "    input(\"Press Enter to continue...\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def readJson(filename):\n",
        "    if not os.path.isfile(filename):\n",
        "        logError('Warning: No such file %s!' % filename)\n",
        "        return None\n",
        "\n",
        "    with open(filename) as f:\n",
        "        try:\n",
        "            data = json.load(f)\n",
        "        except:\n",
        "            data = None\n",
        "\n",
        "    if data is None:\n",
        "        logError('Warning: Could not read file %s!' % filename)\n",
        "        return None\n",
        "\n",
        "    return data\n",
        "\n",
        "def preparePath(path, clear = False):\n",
        "    if not os.path.isdir(path):\n",
        "        os.makedirs(path, 0o777)\n",
        "    if clear:\n",
        "        files = os.listdir(path)\n",
        "        for f in files:\n",
        "            fPath = os.path.join(path, f)\n",
        "            if os.path.isdir(fPath):\n",
        "                shutil.rmtree(fPath)\n",
        "            else:\n",
        "                os.remove(fPath)\n",
        "\n",
        "    return path\n",
        "\n",
        "def logError(msg, critical = False):\n",
        "    print(msg)\n",
        "    if critical:\n",
        "        sys.exit(1)\n",
        "\n",
        "\n",
        "def cropImage(img, bbox):\n",
        "    bbox = np.array(bbox, int)\n",
        "\n",
        "    aSrc = np.maximum(bbox[:2], 0)\n",
        "    bSrc = np.minimum(bbox[:2] + bbox[2:], (img.shape[1], img.shape[0]))\n",
        "\n",
        "    aDst = aSrc - bbox[:2]\n",
        "    bDst = aDst + (bSrc - aSrc)\n",
        "\n",
        "    res = np.zeros((bbox[3], bbox[2], img.shape[2]), img.dtype)    \n",
        "    res[aDst[1]:bDst[1],aDst[0]:bDst[0],:] = img[aSrc[1]:bSrc[1],aSrc[0]:bSrc[0],:]\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    print('DONE')\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00002  00002.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}